{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'onca.mp4'\n",
    "# 8 frames inseridos a cada par de frames consecutivos do vídeo original\n",
    "fator = 8 \n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  criar os vídeos de output\n",
    "# interpolacao por repeticao\n",
    "outrep_width = width\n",
    "outrep_height = height\n",
    "# interpolacao linear\n",
    "outlin_width = width\n",
    "outlin_height = height\n",
    "# interpolacao por fluxo optico\n",
    "outopt_width = width\n",
    "outopt_height = height\n",
    "# video com os 3 métodos combinados lado a lado\n",
    "outcomb_width = 3*width \n",
    "outcomb_height = height\n",
    "\n",
    "# Criar objeto VideoWriter para salvar os vídeos\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "outrep_path = 'out_rep.mp4'\n",
    "outlin_path = 'out_lin.mp4'\n",
    "outopt_path = 'out_opt.mp4'\n",
    "outcomb_path = 'out_comb.mp4'\n",
    "\n",
    "outrep = cv2.VideoWriter(outrep_path, fourcc, fps, (outrep_width, outrep_height))\n",
    "outlin = cv2.VideoWriter(outlin_path, fourcc, fps, (outlin_width, outlin_height))\n",
    "outopt = cv2.VideoWriter(outopt_path, fourcc, fps, (outopt_width, outopt_height))\n",
    "outcomb = cv2.VideoWriter(outcomb_path, fourcc, fps, (outcomb_width, outcomb_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para combinar os frames dos vídeos em um único frame\n",
    "def combinar_frames(frames):\n",
    "    # Define as dimensões do novo frame\n",
    "    height = frames[0][0].shape[0]\n",
    "    width = frames[0][0].shape[1]\n",
    "    channels = frames[0][0].shape[2]\n",
    "    combined_frame = np.zeros((height, width * len(frames), channels), dtype=np.uint8)\n",
    "\n",
    "    # Combina os frames dos vídeos\n",
    "    for i, frame in enumerate(frames):\n",
    "        combined_frame[:, i * width : (i + 1) * width, :] = frame[0]\n",
    "\n",
    "    return combined_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando:  10 %\n",
      "Processando:  20 %\n",
      "Processando:  30 %\n",
      "Processando:  40 %\n",
      "Processando:  50 %\n",
      "Processando:  60 %\n",
      "Processando:  70 %\n",
      "Processando:  80 %\n",
      "Processando:  90 %\n",
      "Processando:  100 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mapa das coordenadas x e y (video original) - para o método por fluxo ótico\n",
    "coord_x, coord_y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "cont_frames = 0; total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT); bloco = int(total_frames/10)\n",
    "\n",
    "#rebobinar o vídeo original para o início\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, prev_frame = cap.read()\n",
    "while cap.isOpened():\n",
    "    cont_frames += 1\n",
    "\n",
    "    #imprimir o progresso do processamento\n",
    "    if cont_frames % bloco== 0:\n",
    "        print('Processando: ', int(cont_frames/bloco)*10, '%')\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    # sequencia comeca com o frame anterior (prev_frame)\n",
    "    frame_repeat = cv2.resize(prev_frame, (outrep_width, outrep_height))\n",
    "    frame_linear = cv2.resize(prev_frame, (outlin_width, outlin_height))\n",
    "    frame_optflow = cv2.resize(prev_frame, (outopt_width, outopt_height))\n",
    "\n",
    "    frame_combinado = combinar_frames([[frame_repeat], [frame_linear], [frame_optflow]])\n",
    "    frame_combinado = cv2.resize(frame_combinado, (outcomb_width, outcomb_height))\n",
    "    # escreve cada frame no video de saida correspondente\n",
    "    outrep.write(frame_repeat)\n",
    "    outlin.write(frame_linear)\n",
    "    outopt.write(frame_optflow)\n",
    "    outcomb.write(frame_combinado)\n",
    "    \n",
    "    # Efetuar o fluxo ótico\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calcular o fluxo ótico.  Use o método de Farneback já implementado no OpenCV\n",
    "    # os parâmetros do método são:\n",
    "    # prev_gray: frame anterior em escala de cinza\n",
    "    # gray: frame atual em escala de cinza\n",
    "    # None: sem máscara\n",
    "    # 0.5: pirâmide de escala, fator de escala\n",
    "    # 3: número de níveis da pirâmide\n",
    "    # 15: tamanho da janela de vizinhança\n",
    "    # 3: número de iterações do algoritmo\n",
    "    # 5: tamanho da janela de média para suavização\n",
    "    # 1.2: desvio padrão do filtro gaussiano\n",
    "    # 0: flags\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # inserir frames intermediários\n",
    "    for i in range(1, fator):\n",
    "        # Interpolação por repetição\n",
    "        frame_repeat = prev_frame\n",
    "\n",
    "        # Interpolação linear\n",
    "        # a função addWeighted() do OpenCV pode ser usada para combinar dois frames\n",
    "        # por interpolação linear.  Para combinar frames é melhor usar a função, que evita\n",
    "        # que você se preocupe com o tipo numérico e problemas de arredondamento\n",
    "        frame_linear = cv2.addWeighted(prev_frame, (fator - i) / fator,frame, i / fator, 0)\n",
    "\n",
    "        # Interpolação por fluxo ótico\n",
    "        # modificando as coordenadas x e y de acordo com o fluxo ótico\n",
    "        # o mapa map_x contém as coordenadas x de cada pixel do frame atual\n",
    "        # ele deve ser calculado a partir do mapa de coordenadas x original (coord_x)\n",
    "        # e do fluxo ótico (flow)\n",
    "        # use uma interpolação linear, com peso (i/fator), para incluir a fração do fluxo ótico que deve ser considerada\n",
    "        # não é preciso usar a função cv2.addWeighted() aqui!  São apenas matrizes de números reais.\n",
    "        map_x = coord_x #complete aqui# \n",
    "        map_y = coord_y #complete aqui#\n",
    "        frame_optflow = cv2.remap(prev_frame, map_x.astype(np.float32),\\\n",
    "                        map_y.astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "        # finalmente, faça a interpolação linear entre o próximo frame e o\n",
    "        # frame transformado com fluxo ótico.\n",
    "        # quais os pesos você deve usar?\n",
    "        peso_fluxo_otico = (fator - i)/fator\n",
    "        peso_proximo_frame = 1-peso_fluxo_otico\n",
    "        frame_optflow = cv2.addWeighted(frame_optflow, peso_fluxo_otico, frame, peso_proximo_frame, 0)\n",
    "\n",
    "        # Combina os frames dos vídeos (repetição, linear e fluxo ótico)\n",
    "        frame_combinado = combinar_frames([[frame_repeat], [frame_linear], [frame_optflow]])\n",
    "        #frame_combinado = cv2.resize(frame_combinado, (outcomb_width, outcomb_height))\n",
    "        # escreve cada frame no video de saida correspondente\n",
    "        outrep.write(frame_repeat)\n",
    "        outlin.write(frame_linear)\n",
    "        outopt.write(frame_optflow)\n",
    "        outcomb.write(frame_combinado)\n",
    "\n",
    "    prev_frame = frame\n",
    "\n",
    "cap.release()\n",
    "outrep.release()\n",
    "outlin.release()\n",
    "outopt.release()\n",
    "outcomb.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Frames com interpolação por repetição:\n",
    "Conforme é possível verificar no resultado, existem transições bruscas entre os frames, causado pela repetição do frame anterior que é copiado.\n",
    "\n",
    "- Frames com interpolação linear:\n",
    "A transição é mais suave devido ao efeito de média utilizado para interpolar o frame intermediária, mas o movimeento ao fundo da cena ainda não apresenta uma transição muito suave.\n",
    "\n",
    "- Frames com interpolação de fluxo ótico:\n",
    "Apresenta a melhor transição, pois, levando em conta a trajetória dos objetos, o frames intermeediários preservam etalahes do movimento, e transições bruscas e borrões são quase imperceptíveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "O fluxo ótico dos pontos de destaque, para cada pixel, é dado pela seguinte equação:\n",
    "\n",
    "$$\n",
    "F = \\frac{v_{cam} d_f}{60d}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "$v_{cam}$: velocidade da câmera (pixeis/s)\n",
    "\n",
    "$d_f$: distância focal (pixeis)\n",
    "\n",
    "$d$ distância entre o Objeto e a câmera\n",
    "\n",
    "Como a câmera gera um vídeo de $60$ frames por segundo, sua velocidade (dada em pixeis/s) exige a divisão por $60$.\n",
    "\n",
    "Assim:\n",
    "\n",
    "$$d = \\frac{v_{cam} d_f}{60 F}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "De acordo com a fórmula do item anterior, à medida que $d\\to \\infty$, $F\\to 0$, de forma que quanto maior a distância, menor será o fluxo ótico. Esse resultado corresponde ao esperado: intuitivamente, se a distância entre eo objeto e a câmera cresce, o fluxo ótico se torna menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst Frame\u001b[39m\u001b[38;5;124m\"\u001b[39m, select_point)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFirst Frame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(point) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('gatinho.mp4')\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to load video.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Convert the first frame to grayscale\n",
    "gray_first = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define the point to be tracked\n",
    "point = []\n",
    "\n",
    "def select_point(event, x, y, flags, param):\n",
    "    global point\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = [(x, y)]\n",
    "        cv2.circle(first_frame, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"First Frame\", first_frame)\n",
    "\n",
    "cv2.namedWindow(\"First Frame\")\n",
    "cv2.setMouseCallback(\"First Frame\", select_point)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"First Frame\", first_frame)\n",
    "    if len(point) > 0:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow(\"First Frame\")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize  = (15, 15),\n",
    "                 maxLevel = 2,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(first_frame)\n",
    "\n",
    "# Convert point to numpy array\n",
    "p0 = np.array([point], dtype=np.float32)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, 30.0, (first_frame.shape[1], first_frame.shape[0]))\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(gray_first, gray_frame, p0, None, **lk_params)\n",
    "    \n",
    "    if st[0][0] == 1:\n",
    "        a, b = p1.ravel()\n",
    "        a, b = int(a), int(b)  # Convert to integers\n",
    "        cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
    "        mask = cv2.line(mask, tuple(p0.ravel().astype(int)), (a, b), (0, 255, 0), 2)\n",
    "        frame = cv2.add(frame, mask)\n",
    "        p0 = p1\n",
    "        gray_first = gray_frame.copy()\n",
    "\n",
    "    out.write(frame)\n",
    "    if frame_count % 20 == 0:  # \n",
    "        _, img = cv2.imencode('.jpg', frame)\n",
    "        final_image = 'final_frame.jpg'\n",
    "        cv2.imwrite(final_image, frame)\n",
    "        display(Image(data=img))\n",
    "        clear_output(wait=True)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
